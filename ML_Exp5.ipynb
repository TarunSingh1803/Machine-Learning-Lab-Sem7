{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a5335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dfe31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tarun Singh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Tarun Singh\\AppData\\Local\\Temp\\ipykernel_23304\\1869135165.py:10: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "First 5 records:      v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"spam.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"uciml/sms-spam-collection-dataset\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like\n",
    "  # sql_query or pandas_kwargs. See the\n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    "  pandas_kwargs={'encoding': 'latin-1'}\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f791e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v1'] = df['v1'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a8d614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tarun\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Tarun\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Tarun\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Tarun\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cb26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()   ## Convert to lowercase\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])    # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)     # Remove numbers\n",
    "    tokens = nltk.word_tokenize(text, language='english') # Specify language as english\n",
    "    processed_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens if word not in stop_words\n",
    "    ]\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf1c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data After Preprocessing ---\n",
      "                                                  v2  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                   processed_message  \n",
      "0  go jurong point crazy available bugis n great ...  \n",
      "1                            ok lar joking wif u oni  \n",
      "2  free entry wkly comp win fa cup final tkts st ...  \n",
      "3                u dun say early hor u c already say  \n",
      "4           nah dont think go usf life around though  \n"
     ]
    }
   ],
   "source": [
    "df['processed_message'] = df['v2'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\n--- Data After Preprocessing ---\")\n",
    "print(df[['v2', 'processed_message']].head())\n",
    "\n",
    "\n",
    "X = df['processed_message']\n",
    "y = df['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of TF-IDF training matrix: (4457, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and fit the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nShape of TF-IDF training matrix: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5462d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the Model... ---\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "print(\"\\n--- Training the Model... ---\")\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7cd4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.9641 (96.41%)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[965   1]\n",
      " [ 39 110]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.96      1.00      0.98       966\n",
      "    Spam (1)       0.99      0.74      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "# This shows True/False positives and negatives\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "# This shows precision, recall, and f1-score for each class\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham (0)', 'Spam (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e88562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: 'URGENT! You have won a 1 week FREE membership in our $10,000 Prize Jackpot! Text the word: CLAIM to No: 81010'\n",
      "Prediction: Spam\n",
      "\n",
      "Message: 'Hi, can we reschedule our meeting to 1 PM tomorrow?'\n",
      "Prediction: Ham\n"
     ]
    }
   ],
   "source": [
    "def predict_message(message):\n",
    "    preprocessed_message = preprocess_text(message)\n",
    "    vectorized_message = tfidf_vectorizer.transform([preprocessed_message])\n",
    "    prediction = nb_classifier.predict(vectorized_message)\n",
    "\n",
    "    return \"Spam\" if prediction[0] == 1 else \"Ham\"\n",
    "\n",
    "\n",
    "spam_example = \"URGENT! You have won a 1 week FREE membership in our $10,000 Prize Jackpot! Text the word: CLAIM to No: 81010\"\n",
    "ham_example = \"Hi, can we reschedule our meeting to 1 PM tomorrow?\"\n",
    "\n",
    "print(f\"Message: '{spam_example}'\\nPrediction: {predict_message(spam_example)}\\n\")\n",
    "print(f\"Message: '{ham_example}'\\nPrediction: {predict_message(ham_example)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86648c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
